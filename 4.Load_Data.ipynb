{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Needed Data to run simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\savva\\AppData\\Local\\Temp\\ipykernel_15784\\2739327659.py:31: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  Strovolides_Loads_Measurement.index = pd.to_datetime(Strovolides_Loads_Measurement.index)\n"
     ]
    }
   ],
   "source": [
    "import pandapower as pp #import pandapower\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "import pandapower.networks as nw\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from scipy import stats\n",
    "import warnings\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import truncnorm\n",
    "from datetime import datetime\n",
    "\n",
    "# Path to your Excel file\n",
    "file_path = 'PV_Profile_Cyprus.xlsx'\n",
    "\n",
    "# Read the Excel file into a DataFrame\n",
    "PV_profile_Cyprus = pd.read_excel(file_path,index_col=0) # 24 hour per kw historical rooftop production for different months \n",
    "\n",
    "file_path = 'annual_consumption_profiles_cyprus.npy'  # A lot of load profiles from nandos (Australia)\n",
    "Load_profile_cyprus=np.load(file_path)/1000\n",
    "# Load_profile_cyprus=load_profile_cyprus/1000\n",
    "\n",
    "# Load the Excel file\n",
    "file_path = 'EV_Data_Cyprus.xlsx' \n",
    "\n",
    "# Read the 'Departure' and 'Arrival' sheets, ignoring the first row\n",
    "departure = pd.read_excel(file_path, sheet_name='Departure', skiprows=1)\n",
    "arrival = pd.read_excel(file_path, sheet_name='Arrival', skiprows=1)\n",
    "distance = pd.read_excel(file_path, sheet_name='Distance', skiprows=1)\n",
    "\n",
    "# Read the specified sheet into a DataFrame\n",
    "PV_Data = pd.read_excel('PV_Insallation_Historical_Data.xlsx')\n",
    "\n",
    "# Drop rows where 'Power' or 'Phase' columns have NaN values\n",
    "PV_Data = PV_Data.dropna(subset=['Power', 'Phase'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############--------------------------------------- For Arrival t-student -------------------------------------#########################\n",
    "# Fit the Student's t-distribution to the data\n",
    "df, loc_arrival, scale_arrival = stats.t.fit(arrival)\n",
    "# Parameters for truncation\n",
    "a, b = 0, 23  # Truncation limits\n",
    "\n",
    "# Standardize the limits for truncnorm\n",
    "a_std = (a - loc_arrival) / scale_arrival\n",
    "b_std = (b - loc_arrival) / scale_arrival\n",
    "\n",
    "# Create the truncated normal distribution\n",
    "truncated_normal_arrival = stats.truncnorm(a_std, b_std, loc=loc_arrival, scale=scale_arrival)\n",
    "\n",
    "############--------------------------------------- Distance for Weekdays Probabilities Selection using Histogram method -------------------------------------#########################\n",
    "\n",
    "# Step 1: Count the frequency of each unique value\n",
    "value_counts_weekdays = pd.Series(distance.iloc[:,0][distance.iloc[:,0]<300]).value_counts()\n",
    "\n",
    "# Step 2: Calculate probabilities\n",
    "values_weekdays = value_counts_weekdays.index  # Unique values\n",
    "probabilities_weekdays = value_counts_weekdays / value_counts_weekdays.sum()  # Normalize counts to probabilities\n",
    "\n",
    "# random_value = np.random.choice(values_weekdays, p=probabilities_weekdays)\n",
    "\n",
    "############--------------------------------------- Distance for Weekends, Probabilities Selection using Histogram method -------------------------------------#########################\n",
    "\n",
    "# Step 1: Count the frequency of each unique value\n",
    "value_counts_weekends = pd.Series(distance.iloc[:,1][distance.iloc[:,1]<300]).value_counts()\n",
    "\n",
    "# Step 2: Calculate probabilities\n",
    "values_weekends = value_counts_weekends.index  # Unique values\n",
    "probabilities_weekends = value_counts_weekends / value_counts_weekends.sum()  # Normalize counts to probabilities\n",
    "\n",
    "# random_value = np.random.choice(values_weekends, p=probabilities_weekends)\n",
    "\n",
    "######################---------------- For Arrival and Departure Normal Distribution -----------------------------------################################## \n",
    "\n",
    "# Step 1: Calculate mean and standard deviation\n",
    "mean_arrival = arrival.mean()\n",
    "std_dev_arrival = arrival.std()\n",
    "# print(\"the Mean value for arrival are \" + str(mean_arrival.item()))\n",
    "# print(\"the Std value for arrival are \" + str(std_dev_arrival.item()))\n",
    "\n",
    "mean_departure = departure.mean()\n",
    "std_dev_departure = departure.std()\n",
    "# print(\"the Mean value for departure are \" + str(mean_departure.item()))\n",
    "# print(\"the Std value for departure are \" + str(std_dev_departure.item()))\n",
    "\n",
    "# Step 2: Create the normal distribution\n",
    "normal_dist_arrival = norm(loc=mean_arrival, scale=std_dev_arrival)\n",
    "normal_dist_departure = norm(loc=mean_departure, scale=std_dev_departure)\n",
    "\n",
    "######################---------------- For Distance Normal Distribution -----------------------------------################################## \n",
    "\n",
    "# Step 1: Calculate mean and standard deviation\n",
    "mean_distance_wd = distance.iloc[:,0].mean()\n",
    "std_dev_distance_wd = distance.iloc[:,0].std()\n",
    "# print(\"the Mean value for weekdays distance are \" + str(mean_distance_wd))\n",
    "# print(\"the Std value for weekdays distance are \" + str(std_dev_distance_wd))\n",
    "\n",
    "mean_distance_wk = distance.iloc[:,1].mean()\n",
    "std_dev_distance_wk = distance.iloc[:,1].std()\n",
    "# print(\"the Mean value for weekends distance are \" + str(mean_distance_wk))\n",
    "# print(\"the Std value for weekends distance are are \" + str(std_dev_distance_wk))\n",
    "\n",
    "# Step 2: Create the normal distribution\n",
    "normal_dist_distance_wd = norm(loc=mean_distance_wd, scale=std_dev_distance_wd)\n",
    "normal_dist_distance_wk = norm(loc=mean_distance_wk, scale=std_dev_distance_wk)\n",
    "\n",
    "\n",
    "############---------------- Truncate Normal Distribution for Arrival and Departure -------------------------###################################\n",
    "\n",
    "# Set bound to the distribution\n",
    "a, b = (0 - mean_arrival.item()) / std_dev_arrival.item(), (23 - mean_arrival.item()) / std_dev_arrival.item()\n",
    "# truncated_normal_arrival = truncnorm(a, b, loc=mean_arrival.item(), scale=std_dev_arrival.item())\n",
    "\n",
    "c, d = (0 - mean_departure.item()) / std_dev_departure.item(), (23 - mean_departure.item()) / std_dev_departure.item()\n",
    "truncated_normal_departure = truncnorm(c, d, loc=mean_departure.item(), scale=std_dev_departure.item())\n",
    "\n",
    "\n",
    "################## ------------- PV power for 1-phase and 3-phase with Probabilities Selection using Histogram method ------------------- ##########################\n",
    "\n",
    "one_phase_power = PV_Data[PV_Data['Phase'] != '3Φ']['Power']\n",
    "one_phase_power = pd.to_numeric(one_phase_power, errors='coerce')\n",
    "one_phase_power.dropna(inplace=True)\n",
    "one_phase_power[one_phase_power > 500] = one_phase_power[one_phase_power>500]/1000\n",
    "one_phase_power = one_phase_power[one_phase_power <= 4.2]\n",
    "\n",
    "# Step 1: Count the frequency of each unique value\n",
    "value_counts_one_phase = pd.Series(one_phase_power).value_counts()\n",
    "\n",
    "# Step 2: Calculate probabilities\n",
    "values_one_phase = value_counts_one_phase.index  # Unique values\n",
    "probabilities_one_phase = value_counts_one_phase / value_counts_one_phase.sum()  # Normalize counts to probabilities\n",
    "\n",
    "# Step 3: Randomly select a value based on probabilities\n",
    "# random_value = np.random.choice(values_one_phase, p=probabilities_one_phase)\n",
    "\n",
    "three_phase_power = PV_Data[PV_Data['Phase'] == '3Φ']['Power']\n",
    "three_phase_power = pd.to_numeric(three_phase_power, errors='coerce')\n",
    "three_phase_power.dropna(inplace=True)\n",
    "three_phase_power[three_phase_power > 500] = three_phase_power[three_phase_power>500]/1000\n",
    "three_phase_power = three_phase_power[three_phase_power <= 10.4]\n",
    "\n",
    "# Step 1: Count the frequency of each unique value\n",
    "value_counts_three_phase = pd.Series(three_phase_power).value_counts()\n",
    "\n",
    "# Step 2: Calculate probabilities\n",
    "values_three_phase = value_counts_three_phase.index  # Unique values\n",
    "probabilities_three_phase = value_counts_three_phase / value_counts_three_phase.sum()  # Normalize counts to probabilities\n",
    "\n",
    "PV_Proba = [{\n",
    "    \"values_one_phase\": values_one_phase,\n",
    "    \"probabilities_one_phase\": probabilities_one_phase,\n",
    "    \"values_three_phase\": values_three_phase,\n",
    "    \"probabilities_three_phase\": probabilities_three_phase\n",
    "}]\n",
    "# Step 3: Randomly select a value based on probabilities\n",
    "# random_value = np.random.choice(values_three_phase, p=probabilities_three_phase)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the cos(φ) linear dependence function for P > 0.4\n",
    "def calculate_cos_phi(p):\n",
    "    if p <= 0.4:\n",
    "        return 1.0  # cos(φ) = 1 below P = 0.4\n",
    "    else:\n",
    "        return 1.0 - 0.1 * (p - 0.4) / (1.0 - 0.4)  # Linear reduction to 0.9 at P = 1\n",
    "\n",
    "# Compute Q profile\n",
    "def calculate_q_profile(pv_profile):\n",
    "    q_profile = pd.DataFrame(index=pv_profile.index, columns=pv_profile.columns)\n",
    "    \n",
    "    for column in pv_profile.columns:\n",
    "        p_values = pv_profile[column]\n",
    "        q_values = []\n",
    "        \n",
    "        for p in p_values:\n",
    "            cos_phi = calculate_cos_phi(p)  # Calculate cos(φ)\n",
    "            phi = np.arccos(cos_phi)        # Calculate φ (angle in radians)\n",
    "            q = p * np.tan(phi)             # Calculate Q\n",
    "            q_values.append(q)\n",
    "        \n",
    "        q_profile[column] = q_values\n",
    "    \n",
    "    return q_profile\n",
    "\n",
    "# Calculate the Q profile\n",
    "q_pv_profile_cyprus = calculate_q_profile(PV_profile_Cyprus)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
